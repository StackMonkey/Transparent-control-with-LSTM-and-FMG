{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_excel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert time series into supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # Forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # Put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# Create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return array(diff)\n",
    "\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "    # Extract raw values\n",
    "    raw_values = series.values\n",
    "    # Difference data to make it stationary\n",
    "    diff_series = difference(raw_values, 1)\n",
    "    # Rescale values to -1, 1\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_values = scaler.fit_transform(diff_series.reshape(-1, 1))\n",
    "    print(max(diff_series))\n",
    "    print(min(diff_series))\n",
    "    # Transform into supervised learning problem X, y\n",
    "    supervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "    supervised_values = supervised.values\n",
    "    # Split into train and test sets\n",
    "    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "    # Inverse transform test set to get original values\n",
    "    test_values = scaler.inverse_transform(test[:, :])[:, 0]  # Extract actual values\n",
    "\n",
    "    return scaler, train, test, test_values  # Return all needed data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n",
    "    # Assume train, n_lag, nb_epoch, n_batch are defined elsewhere\n",
    "    X, y = train[:, 0:n_lag], train[:, n_lag:]\n",
    "    X = X.reshape(X.shape[0], n_lag, 1)  # Reshape X for LSTM\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, input_shape=(X.shape[1], X.shape[2]),unroll=True)) # Remove batch_input_shape\n",
    "    model.add(Dense(y.shape[1],'tanh'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # fit network\n",
    "    model.fit(X, y, epochs=nb_epoch, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "# Make one forecast with an LSTM\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "    # Reshape input pattern to [samples, timesteps, features]\n",
    "    X = X.reshape(1, len(X), 1)  # Ensure there's one feature per timestep\n",
    "    # Make forecast\n",
    "    forecast = model.predict(X, batch_size=n_batch)\n",
    "    # Convert to array\n",
    "    return [x for x in forecast[0, :]]\n",
    "\n",
    "# Evaluate the persistence model\n",
    "def make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n",
    "    forecasts = list()\n",
    "    for i in range(len(test)):\n",
    "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "        # Make forecast\n",
    "        forecast = forecast_lstm(model, X, n_batch)\n",
    "        # Store the forecast\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts\n",
    "\n",
    "# Invert differenced forecast\n",
    "def inverse_difference(last_ob, forecast):\n",
    "    # Invert first forecast\n",
    "    inverted = list()\n",
    "    inverted.append(forecast[0] + last_ob)\n",
    "    # Propagate difference forecast using inverted first value\n",
    "    for i in range(1, len(forecast)):\n",
    "        inverted.append(forecast[i] + inverted[i-1])\n",
    "    return inverted\n",
    "\n",
    "# Inverse data transform on forecasts\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        # Create array from forecast\n",
    "        forecast = array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "        # Invert scaling\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "        # Invert differencing\n",
    "        index = len(series) - n_test + i - 1\n",
    "        last_ob = series.values[index]\n",
    "        inv_diff = inverse_difference(last_ob, inv_scale)\n",
    "        # Store\n",
    "        inverted.append(inv_diff)\n",
    "    return inverted\n",
    "\n",
    "# Evaluate the RMSE for each forecast time step\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        actual = [row[i] for row in test]\n",
    "        predicted = [forecast[i] for forecast in forecasts]\n",
    "        rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "        print('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "\n",
    "# Plot the forecasts in the context of the original dataset\n",
    "def plot_forecasts(series, forecasts, n_test):\n",
    "    # Plot the entire dataset in blue\n",
    "    pyplot.plot(series.values)\n",
    "    # Plot the forecasts in red\n",
    "    for i in range(len(forecasts)):\n",
    "        off_s = len(series) - n_test + i - 1\n",
    "        off_e = off_s + len(forecasts[i]) + 1\n",
    "        xaxis = [x for x in range(off_s, off_e)]\n",
    "        yaxis = [series.values[off_s]] + forecasts[i]\n",
    "        pyplot.plot(xaxis, yaxis, color='red')\n",
    "    # Show the plot\n",
    "    pyplot.xlim(left=2000)\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "csv_path = 'TorqueData_noFriction_NL_NG.xlsx'\n",
    "series = pd.read_excel(csv_path)\n",
    "series = series['Torque']\n",
    "#series = combinedSeries['torque']\n",
    "# Configure\n",
    "n_lag = 5\n",
    "n_seq = 1\n",
    "n_test = round(0.3 * len(series))  # Or whatever number of tests you want\n",
    "n_epochs = 20  # Number of epochs for training\n",
    "n_batch = 1  # Batch size\n",
    "n_neurons = 2  # Number of neurons in the LSTM layer\n",
    "pyplot.plot(series.values)\n",
    "# Prepare data\n",
    "scaler, train, test,test_values = prepare_data(series, n_test, n_lag, n_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = fit_lstm(train, n_lag, n_seq, n_batch, n_epochs, n_neurons)\n",
    "model.save('LSTMMM2.keras') # Add .keras extension to the filename\n",
    "# make forecasts\n",
    "forecasts = make_forecasts(model, n_batch, train, test, n_lag, n_seq)\n",
    "forecasts_diff=forecasts\n",
    "# inverse transform forecasts and test\n",
    "\n",
    "forecasts = inverse_transform(series, forecasts, scaler, n_test)\n",
    "actual = [row[n_lag:] for row in test]\n",
    "actual = inverse_transform(series, actual, scaler, n_test)\n",
    "# evaluate forecasts\n",
    "evaluate_forecasts(actual, forecasts, n_lag, n_seq)\n",
    "# plot forecasts\n",
    "plot_forecasts(series, forecasts, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bluetooth\n",
    "import serial\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import struct\n",
    "baud = 921600\n",
    "dataNumBytes = 1\n",
    "CONNECTED = False\n",
    "POST_PROCESSING_DONE = False\n",
    "PREDICTING = True\n",
    "s = serial.Serial(baudrate=baud,timeout=3, write_timeout=3,bytesize=8)\n",
    "def get_serial_ports():\n",
    "    \"\"\"\n",
    "    Lists serial ports.\n",
    "    :return: ([str]) A list of available serial ports\n",
    "    \"\"\"\n",
    "    if sys.platform.startswith('win'):\n",
    "        ports = ['COM%s' % (i + 1) for i in range(256)]\n",
    "    elif sys.platform.startswith('linux') or sys.platform.startswith('cygwin'):\n",
    "        # this excludes your current terminal \"/dev/tty\"\n",
    "        #ports = glob.glob('/dev/tty[A-Za-z]*')\n",
    "        #ports = glob.glob('/dev/[A-Za-z]*')\n",
    "        ports = glob.glob('/dev/rfcomm*')\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "        ports = glob.glob('/dev/tty.*')\n",
    "    else:\n",
    "        raise EnvironmentError('Unsupported platform')\n",
    "\n",
    "    results = []\n",
    "    for port in ports:\n",
    "        try:\n",
    "            s = serial.Serial(port)\n",
    "            s.close()\n",
    "            results.append(port)\n",
    "        except (OSError, serial.SerialException):\n",
    "            pass\n",
    "    print(\"{}\\n\".format(results))\n",
    "    return results\n",
    "\n",
    "def connect():\n",
    "    print(\"Attempting connection... Please wait.\")\n",
    "    serial_ports = get_serial_ports() \n",
    "    for serial_port in serial_ports:\n",
    "        s.port = serial_port\n",
    "        print(\"Handshaking at port: {}\".format(serial_port))\n",
    "        try:\n",
    "            s.open()\n",
    "            s.write(b'k')\n",
    "            time.sleep(1)\n",
    "            print(\"Bytes inWaiting: {}\".format(s.in_waiting))\n",
    "            handshake_return = s.read(1)\n",
    "            print(\"Acknowledgement recieved: {}\".format(handshake_return))               \n",
    "            if handshake_return == b'M':\n",
    "                print(\"Motor device found at port: {}\".format(serial_port))\n",
    "                CONNECTED = True\n",
    "                print(\"Connected = {}\".format(CONNECTED))\n",
    "                s.reset_input_buffer()\n",
    "                break\n",
    "            else:\n",
    "                s.close()\n",
    "                print(\"no device\")    \n",
    "        except:\n",
    "            if s.is_open:\n",
    "                s.close()\n",
    "            continue\n",
    "def get_sample():        \n",
    "        data_buffer = list()\n",
    "        data = s.read(8)\n",
    "        if len(data) == 8:\n",
    "            for j in range(8):\n",
    "                value = struct.unpack('f', data[j])\n",
    "                data_buffer.append(value)\n",
    "        else:\n",
    "            data_buffer = [0.0,0.0]\n",
    "        return data_buffer\n",
    "\n",
    "connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_float_from_esp32():\n",
    "    # Read line from serial and decode it to a float\n",
    "    line = s.readline().decode('utf-8').strip()\n",
    "    if line:\n",
    "        try:\n",
    "            received_value = float(line)\n",
    "            print(f\"Received float from ESP32 via Bluetooth: {received_value}\")\n",
    "            return received_value\n",
    "        except ValueError:\n",
    "            print(\"Error: Could not convert received data to float.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 5\n",
    "def prepare_dataNew(series, n_test, n_lag, n_seq):\n",
    "    # Extract raw values\n",
    "    raw_values = series\n",
    "    # Difference data to make it stationary\n",
    "    diff_series = difference(raw_values, 1)\n",
    "    # Rescale values to -1, 1\n",
    "    #scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_values = scaler.fit_transform(diff_series.reshape(-1, 1))\n",
    "    print(max(diff_series))\n",
    "    print(min(diff_series))\n",
    "    # Transform into supervised learning problem X, y\n",
    "    # Split into train and test sets\n",
    "    test = scaled_values\n",
    "\n",
    "    return scaler,test  # Return all needed data\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "    # Reshape input pattern to [samples, timesteps, features]\n",
    "    #  # Ensure there's one feature per timestep\n",
    "    X = X.reshape(1, len(X), 1) \n",
    "    # Make forecast\n",
    "    forecast = model.predict(X, batch_size=n_batch)\n",
    "    # Convert to array\n",
    "    return [x for x in forecast[0, :]]\n",
    "\n",
    "# Evaluate the persistence model\n",
    "def make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n",
    "    forecasts = list()\n",
    "    for i in range(len(test)):\n",
    "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "        # Make forecast\n",
    "        forecast = forecast_lstm(model, X, n_batch)\n",
    "        # Store the forecast\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        # Create array from forecast\n",
    "        forecast = array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "        # Invert scaling\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "        # Invert differencing\n",
    "        index = len(series) - n_test + i - 1\n",
    "        last_ob = series[index]\n",
    "        inv_diff = inverse_difference(last_ob, inv_scale)\n",
    "        # Store\n",
    "        inverted.append(inv_diff)\n",
    "    return inverted\n",
    "def plot_forecasts(series, forecasts, n_test):\n",
    "    # Plot the entire dataset in blue\n",
    "    pyplot.plot(series)\n",
    "    # Plot the forecasts in red\n",
    "    for i in range(len(forecasts)):\n",
    "        off_s = len(series) - n_test + i - 1\n",
    "        off_e = off_s + len(forecasts[i]) + 1\n",
    "        xaxis = [x for x in range(off_s, off_e)]\n",
    "        yaxis = [series[off_s]] + forecasts[i]\n",
    "        pyplot.plot(xaxis, yaxis, color='red')\n",
    "    # Show the plot\n",
    "    pyplot.show()\n",
    "def readBuffer():\n",
    "    try:\n",
    "        # Receive the 8-byte buffer\n",
    "        decoded = list()\n",
    "        data = s.read(12)\n",
    "        print(f\"Received data: {data}\")\n",
    "        for i in range(3):\n",
    "            Decode = data[i*4 : i*4+4]\n",
    "            value, = struct.unpack('f', Decode)            \n",
    "            decoded.append(value)\n",
    "        # Unpack the 8 bytes into 2 floats\n",
    "        # 'f' denotes a 4-byte float, and '>' denotes big-endian byte order\n",
    "        #float_values = struct.unpack('>' + 'f' * 2, data)\n",
    "        print(\"Decoded floats:\", decoded)\n",
    "        \n",
    "        return decoded\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startT = time.time()\n",
    "s.write(b'S')\n",
    "Torques1 = [0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "Torques2 = [0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "TorquePre = [0.0,0.0]\n",
    "v = 0\n",
    "actualTau =list()\n",
    "predictedTau = list()\n",
    "angle = list()\n",
    "interactionTorque = list()\n",
    "while startT + 60 > time.time():\n",
    "# Extract raw values\n",
    "    pre1 = TorquePre[0]\n",
    "    pre2 = TorquePre[1]\n",
    "    s.write(b'G')\n",
    "    s.write(b',')\n",
    "    s.write(b'{pre1}')\n",
    "    s.write(b',')\n",
    "    s.write(b'{pre2}')\n",
    "    s.write(b',')\n",
    "    s.write(b'T')\n",
    "    sample = readBuffer()\n",
    "    torque_data1 = sample[0]\n",
    "    angle_data = sample[1]\n",
    "    interactionTorque_data = sample[2]\n",
    "    Torques1[0] = Torques1[1]\n",
    "    Torques1[1] = Torques1[2]\n",
    "    Torques1[2] = Torques1[3]\n",
    "    Torques1[3] = Torques1[4]\n",
    "    Torques1[4] = Torques1[5]\n",
    "    Torques2[0] = Torques2[1]\n",
    "    Torques2[1] = Torques2[2]\n",
    "    Torques2[2] = Torques2[3]\n",
    "    Torques2[3] = Torques2[4]\n",
    "    Torques2[4] = Torques2[5]\n",
    "    Torques1[5] = torque_data1\n",
    "    Torques2[5] = torque_data1\n",
    "    scaler, test = prepare_dataNew(Torques1,n_test,n_lag,n_seq)\n",
    "    print(test)\n",
    "    X = test.reshape((1,5,1))\n",
    "    torquePrediction = model.predict(X)\n",
    "    forecast = inverse_transform(Torques1, torquePrediction, scaler, n_test)\n",
    "    TorquePre = [forecast[0][1], forecast[0][1]]\n",
    "    print(\"printing forecast\")\n",
    "    print(forecast)\n",
    "\n",
    "    actualTau.append(torque_data1)\n",
    "    predictedTau.append(forecast[0][1])\n",
    "    angle.append(angle_data)\n",
    "    interactionTorque.append(interactionTorque_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(angle)):\n",
    "    angle[i] = angle[i]/360\n",
    "for j in range(len(interactionTorque)):\n",
    "    if interactionTorque[j] < -50:\n",
    "        interactionTorque[j] = interactionTorque[j]+114.21\n",
    "    else:\n",
    "        interactionTorque[j] = interactionTorque[j]\n",
    "\n",
    "pyplot.plot(actualTau)\n",
    "pyplot.plot(interactionTorque)\n",
    "pyplot.plot(angle)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Assuming you have your torque and angle data in a DataFrame named 'data'\n",
    "# with columns 'torque' and 'angle'\n",
    "newTorque = pd.read_excel('C:/Users/malth/Documents/GitHub/Transparent-control-with-LSTM-and-FMG/LSTM and RNN examples/torques.xlsx')\n",
    "newAngle = 360*pd.read_excel('C:/Users/malth/Documents/GitHub/Transparent-control-with-LSTM-and-FMG/LSTM and RNN examples/angles.xlsx')\n",
    "newAngle = newAngle.T\n",
    "newAngle.dropna(inplace=True)\n",
    "newTorque = newTorque.T\n",
    "newTorque.dropna(inplace=True)\n",
    "combinedSeries = concat([newTorque,newAngle], axis=1)\n",
    "combinedSeries.columns = ['torque','angle']\n",
    "combinedSeries\n",
    "data = combinedSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new DataFrame with the desired lagged values\n",
    "# Normalize torque\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "torque_scaler = MinMaxScaler()\n",
    "data['torque'] = torque_scaler.fit_transform(data['torque'].values.reshape(-1, 1))\n",
    "\n",
    "# Normalize angle\n",
    "angle_scaler = MinMaxScaler()\n",
    "data['angle'] = angle_scaler.fit_transform(data['angle'].values.reshape(-1, 1))\n",
    "\n",
    "data['torque_lag_1'] = data['torque'].shift(1)\n",
    "data['torque_lag_2'] = data['torque'].shift(2)\n",
    "data['torque_lag_3'] = data['torque'].shift(3)\n",
    "data['torque_lag_4'] = data['torque'].shift(4)\n",
    "data['torque_lag_5'] = data['torque'].shift(5)\n",
    "data['angle_lag_1'] = data['angle'].shift(1)\n",
    "data['angle_lag_2'] = data['angle'].shift(2)\n",
    "data['angle_lag_3'] = data['angle'].shift(3)\n",
    "data['angle_lag_4'] = data['angle'].shift(4)\n",
    "data['angle_lag_5'] = data['angle'].shift(5)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "#X = data[['torque_lag_1', 'torque_lag_2', 'torque_lag_3', 'torque_lag_4', 'torque_lag_5',\n",
    "#         'angle_lag_1', 'angle_lag_2', 'angle_lag_3', 'angle_lag_4', 'angle_lag_5']]\n",
    "#X = data[['torque_lag_5', 'torque_lag_4', 'torque_lag_3', 'torque_lag_2', 'torque_lag_1',\n",
    "#         'angle_lag_5', 'angle_lag_4', 'angle_lag_3', 'angle_lag_2', 'angle_lag_1']]\n",
    "X = data[['torque_lag_5','angle_lag_5', 'torque_lag_4','angle_lag_4', 'torque_lag_3','angle_lag_3', 'torque_lag_2','angle_lag_2', 'torque_lag_1','angle_lag_1']]\n",
    "y = data['torque']\n",
    "\n",
    "# Normalize data (optional but often beneficial)\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "#X_scaled = scaler.fit_transform(X)\n",
    "#y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False,stratify=None)\n",
    "print(X_train.shape[1])\n",
    "# Reshape data for LSTM input\n",
    "#X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "#X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "X_train = X_train.values.reshape(X_train.shape[0], 5, 2)  # Reshape to (samples, timesteps, features)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], 5, 2)\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(5,2)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "#model.add(LSTM(2, input_shape=(5, 2),unroll=True)) # Remove batch_input_shape\n",
    "#model.add(Dense(y_train.shape[1],'tanh'))\n",
    "#model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test loss:\", loss)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "# Invert normalization to get actual torque values\n",
    "predictions_inv = torque_scaler.inverse_transform(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_actual = y_test.values\n",
    "# Create a figure and axes\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_actual, label='Actual')\n",
    "plt.plot(predictions_inv, label='Predicted')\n",
    "plt.title('Actual vs. Predicted Torque')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Torque')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startT = time.time()\n",
    "Torques1 = [0.0,0.0,0.0,0.0,0.0]\n",
    "Torques2 = [0.0,0.0,0.0,0.0,0.0]\n",
    "angles1 = [0.0,0.0,0.0,0.0,0.0]\n",
    "TorquePre = 0.0\n",
    "s.write(b'S')\n",
    "actualTau =list()\n",
    "predictedTau = list()\n",
    "angle = list()\n",
    "interactionTorque = list()\n",
    "while startT + 60 > time.time():\n",
    "# Extract raw values\n",
    "    pre1 = TorquePre\n",
    "    pre2 = TorquePre\n",
    "    s.write(b'G')\n",
    "    s.write(b',')\n",
    "    s.write(b'{pre1}')\n",
    "    s.write(b',')\n",
    "    s.write(b'{pre2}')\n",
    "    s.write(b',')\n",
    "    s.write(b'T')\n",
    "    sample = readBuffer()\n",
    "    torque_data1 = sample[0]\n",
    "    save_t = torque_data1\n",
    "    torque_data1 = np.array(torque_data1)\n",
    "    torque_data1 = torque_data1.reshape(-1,1)\n",
    "    torque_dataScaled = torque_scaler.transform(torque_data1)\n",
    "    angle_data = sample[1]\n",
    "    save_a = angle_data\n",
    "    angle_data = np.array(angle_data)\n",
    "    angle_data = angle_data.reshape(-1,1)\n",
    "    angle_dataScaled = angle_scaler.transform(angle_data)\n",
    "    interactionTorque_data = sample[2]\n",
    "    angles1[0] = angles1[1]\n",
    "    angles1[1] = angles1[2]\n",
    "    angles1[2] = angles1[3]\n",
    "    angles1[3] = angles1[4]\n",
    "    angles1[4] = angle_dataScaled[0][0]\n",
    "    Torques1[0] = Torques1[1]\n",
    "    Torques1[1] = Torques1[2]\n",
    "    Torques1[2] = Torques1[3]\n",
    "    Torques1[3] = Torques1[4]\n",
    "    Torques1[4] = torque_dataScaled[0][0]\n",
    "    Torques2[0] = Torques2[1]\n",
    "    Torques2[1] = Torques2[2]\n",
    "    Torques2[2] = Torques2[3]\n",
    "    Torques2[3] = Torques2[4]\n",
    "    Torques2[4] = torque_dataScaled[0][0]\n",
    "    X = [Torques1[0],angles1[0],Torques1[1],angles1[1],Torques1[2],angles1[2],Torques1[3],angles1[3],Torques1[4],angles1[4]]\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(1, 5, 2)\n",
    "    torquePrediction = model.predict(X)\n",
    "    forecast = torque_scaler.inverse_transform(torquePrediction)\n",
    "    TorquePre = forecast[0]\n",
    "    print(\"printing forecast\")\n",
    "    print(forecast)\n",
    "\n",
    "    actualTau.append(save_t)\n",
    "    predictedTau.append(TorquePre)\n",
    "    angle.append(save_a)\n",
    "    interactionTorque.append(interactionTorque_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(actualTau)\n",
    "pyplot.plot(predictedTau)\n",
    "#pyplot.plot(angle)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
